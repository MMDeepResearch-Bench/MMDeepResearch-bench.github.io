<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>MMDeepResearch-Bench (MMDR-Bench)</title>
  <meta name="description" content="Grounded evaluation and alignment for multimodal deep research agents." />

  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=Noto+Sans+SC:wght@400;500;600;700&display=swap" rel="stylesheet">

  <style>
    :root{
      --bg: #ffffff;
      --fg: #0f172a;
      --muted: #475569;
      --muted2:#64748b;
      --border:#e2e8f0;
      --card:#ffffff;
      --soft:#f8fafc;
      --accent:#4f46e5;
      --accent2:#06b6d4;
      --shadow: 0 12px 28px rgba(2, 6, 23, .08);
      --radius: 14px;
      --max: 1120px;
      --max-content: 980px; /* closer to MMMU max desktop */
    }
    *{ box-sizing:border-box; }
    body{
      margin:0;
      font-family: Inter, "Noto Sans SC", system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, sans-serif;
      color:var(--fg);
      background: var(--bg);
      line-height:1.65;
    }
    a{ color: inherit; text-decoration: none; }
    a:hover{ color: var(--accent); text-decoration: underline; }

    /* --- minimal "bulma-like" helpers for MMMU layout feel --- */
    .container{ max-width: var(--max); margin: 0 auto; padding: 0 18px; }
    .is-max-desktop{ max-width: var(--max-content); margin: 0 auto; }
    .has-text-centered{ text-align: center; }
    .has-text-justified{ text-align: justify; }
    .content p{ margin: 0 0 14px; }
    .content img{ max-width: 100%; height: auto; }

    header{
      position: sticky;
      top: 0;
      z-index: 50;
      background: rgba(255,255,255,.86);
      backdrop-filter: blur(10px);
      border-bottom: 1px solid var(--border);
    }
    .nav{
      max-width: var(--max);
      margin: 0 auto;
      padding: 12px 18px;
      display:flex;
      align-items:center;
      justify-content: space-between;
      gap: 14px;
    }
    .brand{
      display:flex;
      align-items:center;
      gap:10px;
      font-weight: 700;
      letter-spacing: .2px;
    }
    .pill{
      font-size: 12px;
      color: var(--muted2);
      border: 1px solid var(--border);
      padding: 2px 10px;
      border-radius: 999px;
      background: rgba(248,250,252,.7);
    }
    .navlinks{
      display:flex;
      flex-wrap: wrap;
      gap: 14px;
      align-items:center;
      justify-content:flex-end;
      color: var(--muted);
      font-weight: 500;
      font-size: 14px;
    }
    .lang{
      display:inline-flex;
      gap: 8px;
      align-items:center;
      border-left: 1px solid var(--border);
      padding-left: 12px;
      margin-left: 4px;
      color: var(--muted2);
      font-size: 13px;
    }
    .lang a{ text-decoration:none; }
    .lang .active{ color: var(--fg); font-weight: 600; }

    section{
      max-width: var(--max);
      margin: 0 auto;
      padding: 42px 18px;
    }
    h2{
      font-size: 26px;
      margin: 0 0 14px;
      letter-spacing: -.2px;
    }
    h3{
      margin: 0 0 8px;
      font-size: 16px;
      letter-spacing: -.2px;
    }
    p{ margin: 0 0 14px; color: var(--fg); }
    .muted{ color: var(--muted); }
    .muted2{ color: var(--muted2); }

    /* --- Example layout --- */
    .example-col{ grid-column: span 6; }
    @media (max-width: 900px){
      .example-col{ grid-column: span 12; }
    }
    .example-fig{
      width: 100%;
      max-width: 100%;
      height: auto;
    }

    /* --- MMMU-like hero / header block --- */
    .hero-wrap{
      background:
        radial-gradient(900px 260px at 15% 0%, rgba(79,70,229,.10), transparent 60%),
        radial-gradient(900px 260px at 85% 0%, rgba(6,182,212,.10), transparent 60%),
        linear-gradient(180deg, var(--soft), #ffffff 55%);
      border-bottom: 1px solid var(--border);
    }
    .hero{
      max-width: var(--max);
      margin: 0 auto;
      padding: 56px 18px 42px;
    }
    .kicker{
      display:inline-flex;
      align-items:center;
      gap: 10px;
      color: var(--muted2);
      font-size: 12px;
      font-weight: 700;
      text-transform: uppercase;
      letter-spacing: .14em;
    }
    .pub-title{
      font-size: clamp(32px, 5vw, 52px);
      line-height: 1.08;
      margin: 12px 0 10px;
      letter-spacing: -.02em;
    }
    .pub-subtitle{
      max-width: 860px;
      color: var(--muted);
      font-size: 17px;
      margin: 0 auto 18px;
    }
    .pub-authors{
      color: var(--muted2);
      font-size: 14px;
      margin: 0 0 18px;
    }

    /* --- MMMU-like rounded dark buttons row --- */
    .publication-links{
      display:flex;
      gap: 12px;
      flex-wrap: wrap;
      align-items:center;
      justify-content: center;
      margin-top: 10px;
    }
    .button{
      display:inline-flex;
      align-items:center;
      gap: 8px;
      padding: 10px 16px;
      border-radius: 999px;
      border: 1px solid #0b1220;
      background: #0b1220;
      color: #fff;
      font-weight: 650;
      font-size: 14px;
      line-height: 1;
      box-shadow: 0 1px 0 rgba(2,6,23,.06);
    }
    .button:hover{ text-decoration:none; filter: brightness(1.06); color:#fff; }
    .button .icon{
      width: 18px;
      height: 18px;
      display:inline-flex;
      align-items:center;
      justify-content:center;
      font-size: 15px;
    }
    .button.is-light{
      background: #fff;
      color: var(--fg);
      border-color: var(--border);
    }
    .button.is-light:hover{ color: var(--accent); }

    /* --- section ‚Äúband‚Äù like MMMU light hero separators --- */
    .band{
      border-top: 1px solid var(--border);
      border-bottom: 1px solid var(--border);
      background: var(--soft);
      padding: 26px 18px;
    }
    .band-inner{
      max-width: var(--max);
      margin: 0 auto;
      text-align: center;
    }
    .band-title{
      margin: 0;
      font-size: 34px;
      letter-spacing: -.02em;
    }

    /* existing components (kept) */
    .grid{
      display:grid;
      grid-template-columns: repeat(12, 1fr);
      gap: 14px;
    }
    .card{
      background: var(--card);
      border: 1px solid var(--border);
      border-radius: var(--radius);
      padding: 16px 16px;
      box-shadow: var(--shadow);
    }
    .meta-row{
      display:flex;
      flex-wrap:wrap;
      gap: 10px;
      justify-content: center;
      margin-top: 14px;
    }
    .badge{
      display:inline-flex;
      align-items:center;
      gap: 6px;
      font-size: 12px;
      font-weight: 650;
      padding: 4px 10px;
      border-radius: 999px;
      border: 1px solid var(--border);
      background: rgba(248,250,252,.85);
      color: var(--muted);
    }

    figure{ margin: 0; }
    .figure-card{
      background: var(--soft);
      border: 1px solid var(--border);
      border-radius: var(--radius);
      padding: 14px;
    }
    .figure-media{
      background:#fff;
      border: 1px solid var(--border);
      border-radius: 12px;
      padding: 20px;
      display:flex;
      align-items:center;
      justify-content:center;
      overflow: hidden;
    }
    .paper-fig.intro{
      display:block;
      width: 100%;
      height: auto;
      max-width: 100%;
      border-radius: 10px;
    }
    .paper-fig.pipeline{
      display:block;
      width: auto;
      height: auto;
      max-height: 700px;
      max-width: 100%;
      border-radius: 10px;
    }
    .paper-fig{
      display:block;
      max-width: 100%;
      height: auto;
      border-radius: 10px;
    }
    @media (max-width: 768px){
      .paper-fig.intro,
      .paper-fig.pipeline{
        width: 100%;
        max-height: none;
      }
      .figure-media{ padding: 12px; }
    }
    figcaption{
      margin-top: 10px;
      color: var(--muted2);
      font-size: 13px;
    }
    figcaption a{ text-decoration: underline; }

    pre{
      margin: 0;
      background: #0b1220;
      color: #e5e7eb;
      padding: 14px 14px;
      border-radius: 12px;
      overflow-x:auto;
      border: 1px solid rgba(148,163,184,.25);
      font-size: 13px;
      line-height: 1.6;
    }
    code{ font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace; }
    .copy{
      position:absolute;
      top: 12px;
      right: 12px;
      border: 1px solid var(--border);
      background: #fff;
      border-radius: 10px;
      padding: 8px 10px;
      font-weight: 700;
      cursor:pointer;
      font-size: 12px;
    }

    footer{
      border-top: 1px solid var(--border);
      background: #ffffff;
      padding: 28px 18px;
      color: var(--muted2);
    }
    .footer-inner{
      max-width: var(--max);
      margin: 0 auto;
      display:flex;
      flex-wrap:wrap;
      justify-content: space-between;
      gap: 12px;
      font-size: 13px;
    }

    @media (max-width: 880px){
      .navlinks{ display:none; }
    }

    /* Leaderboard Styles (kept) */
    .leaderboard-container {
      background: white;
      border: 1px solid var(--border);
      border-radius: var(--radius);
      overflow: hidden;
      box-shadow: var(--shadow);
      margin-top: 20px;
    }
    .leaderboard-header {
      background: #0b1220;
      color: white;
      padding: 22px 24px;
    }
    .leaderboard-header h3 {
      margin: 0 0 4px;
      font-size: 20px;
      color: white;
    }
    .leaderboard-header p {
      margin: 0;
      opacity: 0.95;
      font-size: 14px;
      color: white;
    }

    .controls {
      padding: 16px 20px;
      background: var(--soft);
      border-bottom: 1px solid var(--border);
      display: flex;
      gap: 12px;
      flex-wrap: wrap;
      align-items: center;
    }
    .filter-group {
      display: flex;
      gap: 8px;
      align-items: center;
    }
    .filter-btn {
      padding: 6px 14px;
      border: 1px solid var(--border);
      background: white;
      border-radius: 999px;
      cursor: pointer;
      font-size: 13px;
      transition: all 0.2s;
      font-weight: 600;
    }
    .filter-btn:hover { border-color: var(--accent); color: var(--accent); }
    .filter-btn.active { background: #0b1220; color: white; border-color: #0b1220; }

    .search-box { flex: 1; min-width: 200px; max-width: 300px; }
    .search-box input {
      width: 100%;
      padding: 8px 12px;
      border: 1px solid var(--border);
      border-radius: 999px;
      font-size: 13px;
      outline: none;
    }
    .search-box input:focus{
      border-color: rgba(79,70,229,.5);
      box-shadow: 0 0 0 3px rgba(79,70,229,.12);
    }

    .table-container { overflow-x: auto; }
    .leaderboard-table { width: 100%; border-collapse: collapse; font-size: 13px; }
    .leaderboard-table thead {
      background: var(--soft);
      position: sticky;
      top: 0;
      z-index: 10;
    }
    .leaderboard-table th {
      padding: 10px 8px;
      text-align: center;
      font-weight: 700;
      color: var(--muted);
      border-bottom: 2px solid var(--border);
      white-space: nowrap;
      cursor: pointer;
      user-select: none;
      font-size: 12px;
    }
    .leaderboard-table th:hover { background: #eef2ff; }
    .leaderboard-table th.sortable::after { content: ' ‚áÖ'; opacity: 0.3; font-size: 10px; }
    .leaderboard-table th.sort-asc::after { content: ' ‚Üë'; opacity: 1; }
    .leaderboard-table th.sort-desc::after { content: ' ‚Üì'; opacity: 1; }
    .metric-group { border-left: 2px solid var(--border); }

    .leaderboard-table td {
      padding: 10px 8px;
      text-align: center;
      border-bottom: 1px solid #f1f3f5;
    }
    .leaderboard-table tr:hover { background: var(--soft); }

    .model-cell {
      text-align: left !important;
      font-weight: 600;
      padding-left: 12px !important;
      position: sticky;
      left: 0;
      background: white;
      z-index: 5;
      min-width: 200px;
    }
    .leaderboard-table tr:hover .model-cell { background: var(--soft); }

    .company-logo {
      display: inline-block;
      margin-right: 8px;
      vertical-align: middle;
      width: 20px;
      height: 20px;
      object-fit: contain;
      opacity: 0.9;
      transition: opacity 0.2s, transform 0.2s;
      flex-shrink: 0;
      border-radius: 4px;
    }
    .model-cell:hover .company-logo { opacity: 1; transform: scale(1.05); }

    .rank {
      display: inline-block;
      width: 22px;
      height: 22px;
      line-height: 22px;
      text-align: center;
      border-radius: 50%;
      margin-right: 6px;
      font-size: 11px;
      font-weight: 800;
    }
    .rank-1 { background: #ffd700; color: #000; }
    .rank-2 { background: #c0c0c0; color: #000; }
    .rank-3 { background: #cd7f32; color: #fff; }
    .rank-other { background: #e9ecef; color: #6c757d; }

    @media (max-width: 768px){
      .controls { flex-direction: column; align-items: stretch; }
      .search-box { max-width: 100%; }
      .model-cell { position: static; }
    }
  </style>

  <script>
(() => {
  let DATA = [
    // Single-Modal, w/o Search
    { category: "single", model: "OpenAI o3-mini", overall: 31.96, read: 53.75, insh: 52.65, stru: 37.11, vef: 13.57, con: 28.45, cov: 33.74, fid: 48.35, sem: 15.47, acc: 90.00, vqa: 12.60 },
    { category: "single", model: "DeepSeek-V3.2", overall: 43.71, read: 75.37, insh: 87.82, stru: 58.16, vef: 19.28, con: 33.34, cov: 45.48, fid: 18.77, sem: 42.19, acc: 83.85, vqa: 12.88 },
    { category: "single", model: "Kimi K2 (Thinking)", overall: 36.91, read: 71.34, insh: 77.27, stru: 47.34, vef: 17.14, con: 23.54, cov: 24.62, fid: 27.20, sem: 42.00, acc: 90.00, vqa: 9.50 },
    { category: "single", model: "Qwen 3 235B (A22B)", overall: 36.04, read: 77.56, insh: 85.74, stru: 54.05, vef: 17.14, con: 35.60, cov: 45.73, fid: 22.98, sem: 20.43, acc: 53.09, vqa: 4.95 },

    // Multimodal, w/o Search
    { category: "multimodal", model: "Qwen 3 VL 235B (A22B)", overall: 35.08, read: 77.01, insh: 86.48, stru: 52.21, vef: 43.57, con: 18.34, cov: 15.25, fid: 10.68, sem: 30.58, acc: 93.52, vqa: 16.98 },
    { category: "multimodal", model: "GPT-4o", overall: 28.62, read: 52.52, insh: 68.41, stru: 40.90, vef: 10.04, con: 10.94, cov: 4.61, fid: 11.89, sem: 24.10, acc: 71.43, vqa: 18.72 },
    { category: "multimodal", model: "GPT-4.1", overall: 36.95, read: 79.34, insh: 89.04, stru: 53.00, vef: 39.29, con: 15.90, cov: 10.06, fid: 5.61, sem: 29.66, acc: 80.56, vqa: 19.92 },
    { category: "multimodal", model: "GPT-4.1 mini", overall: 34.23, read: 71.25, insh: 83.62, stru: 49.60, vef: 12.86, con: 24.20, cov: 25.44, fid: 12.33, sem: 32.62, acc: 89.91, vqa: 13.21 },
    { category: "multimodal", model: "GPT-4.1 nano", overall: 28.07, read: 49.77, insh: 64.82, stru: 37.28, vef: 10.79, con: 18.99, cov: 19.86, fid: 24.42, sem: 27.02, acc: 76.30, vqa: 13.04 },
    { category: "multimodal", model: "GPT-5 mini", overall: 38.49, read: 70.06, insh: 81.73, stru: 47.18, vef: 39.29, con: 20.02, cov: 26.64, fid: 32.61, sem: 33.90, acc: 94.23, vqa: 15.60 },
    { category: "multimodal", model: "GPT-5.1", overall: 32.69, read: 79.34, insh: 89.04, stru: 53.00, vef: 35.71, con: 15.90, cov: 2.30, fid: 13.67, sem: 22.03, acc: 84.29, vqa: 14.32 },
    { category: "multimodal", model: "GPT-5.2", overall: 32.76, read: 69.75, insh: 83.92, stru: 54.31, vef: 46.43, con: 14.00, cov: 1.43, fid: 5.30, sem: 12.83, acc: 50.00, vqa: 9.16 },
    { category: "multimodal", model: "Grok-3", overall: 29.89, read: 75.17, insh: 86.13, stru: 52.24, vef: 20.00, con: 12.57, cov: 5.79, fid: 2.80, sem: 22.18, acc: 68.39, vqa: 13.89 },
    { category: "multimodal", model: "Grok-4 (Fast Reasoning)", overall: 36.10, read: 60.62, insh: 80.49, stru: 52.99, vef: 36.43, con: 17.30, cov: 14.62, fid: 6.12, sem: 28.46, acc: 87.45, vqa: 19.34 },

    // Multimodal, w/ Search
    { category: "multimodal", model: "Claude 4.5 Haiku", overall: 33.67, read: 74.60, insh: 81.80, stru: 53.22, vef: 28.57, con: 17.90, cov: 14.10, fid: 18.56, sem: 25.98, acc: 76.90, vqa: 11.70 },
    { category: "multimodal", model: "Claude 4.5 Sonnet", overall: 33.61, read: 77.63, insh: 82.31, stru: 51.65, vef: 32.14, con: 14.36, cov: 15.09, fid: 16.11, sem: 20.73, acc: 70.13, vqa: 14.41 },
    { category: "multimodal", model: "Claude 4.5 Opus", overall: 33.84, read: 77.81, insh: 83.86, stru: 50.70, vef: 35.00, con: 30.64, cov: 41.14, fid: 21.97, sem: 21.30, acc: 77.21, vqa: 14.75 },
    { category: "multimodal", model: "Gemini 2.5 Flash", overall: 38.40, read: 56.22, insh: 68.58, stru: 55.44, vef: 32.86, con: 25.35, cov: 27.77, fid: 38.30, sem: 40.67, acc: 75.96, vqa: 25.49 },
    { category: "multimodal", model: "Gemini 2.5 Pro", overall: 38.04, read: 80.04, insh: 85.94, stru: 51.44, vef: 38.57, con: 30.18, cov: 28.77, fid: 14.98, sem: 19.47, acc: 92.86, vqa: 12.50 },
    { category: "multimodal", model: "Gemini 3 Flash", overall: 44.43, read: 81.22, insh: 90.22, stru: 52.00, vef: 45.71, con: 31.95, cov: 35.07, fid: 15.42, sem: 36.61, acc: 87.31, vqa: 18.99 },
    { category: "multimodal", model: "Gemini 3 Pro", overall: 44.68, read: 58.05, insh: 75.39, stru: 49.85, vef: 46.43, con: 37.98, cov: 41.85, fid: 6.46, sem: 40.69, acc: 80.44, vqa: 23.15 },

    // Deep Research Agent
    { category: "agent", model: "Tongyi Deep Research (30B-A3B)", overall: 29.02, read: 54.27, insh: 62.67, stru: 40.07, vef: 12.86, con: 25.99, cov: 30.87, fid: 24.25, sem: 20.39, acc: 93.33, vqa: 20.39 },
    { category: "agent", model: "Perplexity Sonar Deep Research", overall: 37.55, read: 62.29, insh: 64.35, stru: 47.80, vef: 27.86, con: 33.12, cov: 41.51, fid: 16.68, sem: 50.79, acc: 87.75, vqa: 21.22 },
    { category: "agent", model: "ChatGPT Deep Research (o3-mini)", overall: 29.50, read: 52.40, insh: 63.61, stru: 37.30, vef: 29.29, con: 10.19, cov: 4.16, fid: 11.07, sem: 27.32, acc: 73.44, vqa: 21.75 },
    { category: "agent", model: "Gemini Deep Research (Gemini 3 Pro)", overall: 49.41, read: 84.53, insh: 89.56, stru: 70.86, vef: 35.71, con: 56.17, cov: 52.84, fid: 31.29, sem: 41.29, acc: 87.54, vqa: 28.45 }
  ];

  let state = { filter: "all", query: "", sortKey: "overall", sortDir: "desc" };
  let tableBody, searchInput, filterBtns, ths;

  function safeNum(x) {
    const n = Number(x);
    return Number.isFinite(n) ? n : -Infinity;
  }

  function getFiltered() {
    const q = state.query.trim().toLowerCase();
    return DATA.filter(row => {
      const okFilter = (state.filter === "all") || (row.category === state.filter);
      const okQuery = !q || String(row.model || "").toLowerCase().includes(q);
      return okFilter && okQuery;
    });
  }

  function sortRows(rows) {
    const { sortKey, sortDir } = state;
    const dir = sortDir === "asc" ? 1 : -1;

    rows.sort((a, b) => {
      if (sortKey === "model") return dir * String(a.model || "").localeCompare(String(b.model || ""));
      return dir * (safeNum(a[sortKey]) - safeNum(b[sortKey]));
    });

    return rows;
  }

  function computeRanks(rows) {
    const tmp = [...rows].sort((a,b) => safeNum(b.overall) - safeNum(a.overall));
    tmp.forEach((r, i) => (r.__rank = i + 1));
  }

  function rankClass(r) {
    if (r === 1) return "rank rank-1";
    if (r === 2) return "rank rank-2";
    if (r === 3) return "rank rank-3";
    return "rank rank-other";
  }

  function fmt(x) {
    const n = Number(x);
    return Number.isFinite(n) ? n.toFixed(2) : "‚Äî";
  }

  function getCompanyLogo(modelName) {
    const model = String(modelName || "").toLowerCase();
    if (model.includes("gpt") || model.includes("openai") || model.includes("chatgpt")) {
      return '<img src="ico/gpt.png" alt="OpenAI" class="company-logo" title="OpenAI" />';
    }
    if (model.includes("claude")) {
      return '<img src="ico/Claude.png" alt="Anthropic" class="company-logo" title="Anthropic" />';
    }
    if (model.includes("gemini")) {
      return '<img src="ico/gemini.png" alt="Google" class="company-logo" title="Google" />';
    }
    if (model.includes("deepseek")) {
      return '<img src="ico/deepseek.png" alt="DeepSeek" class="company-logo" title="DeepSeek" />';
    }
    if (model.includes("qwen") || model.includes("tongyi")) {
      return '<img src="ico/qwen.png" alt="Alibaba" class="company-logo" title="Alibaba" />';
    }
    if (model.includes("kimi")) {
      return '<img src="ico/kimi.png" alt="Moonshot AI" class="company-logo" title="Moonshot AI" />';
    }
    if (model.includes("grok")) {
      return '<img src="ico/grok.png" alt="xAI" class="company-logo" title="xAI" />';
    }
    if (model.includes("perplexity") || model.includes("sonar")) {
      return '<img src="ico/sonar.png" alt="Perplexity" class="company-logo" title="Perplexity" />';
    }
    return '<span class="company-logo" title="Unknown">‚Ä¢</span>';
  }

  function render() {
    if (!tableBody) return;

    const rows = getFiltered();
    computeRanks(rows);
    const sorted = sortRows([...rows]);

    if (!sorted.length) {
      tableBody.innerHTML = `<tr><td colspan="12" style="text-align:center; color:#64748b; padding:18px;">No results</td></tr>`;
      return;
    }

    tableBody.innerHTML = sorted.map(r => `
      <tr data-category="${r.category || ""}">
        <td class="model-cell">
          <span class="${rankClass(r.__rank)}">${r.__rank}</span>
          ${getCompanyLogo(r.model)}
          <span class="model-name">${r.model || ""}</span>
        </td>
        <td>${fmt(r.overall)}</td>
        <td>${fmt(r.read)}</td>
        <td>${fmt(r.insh)}</td>
        <td>${fmt(r.stru)}</td>
        <td>${fmt(r.vef)}</td>
        <td>${fmt(r.con)}</td>
        <td>${fmt(r.cov)}</td>
        <td>${fmt(r.fid)}</td>
        <td>${fmt(r.sem)}</td>
        <td>${fmt(r.acc)}</td>
        <td>${fmt(r.vqa)}</td>
      </tr>
    `).join("");
  }

  function setSortHeaderUI() {
    if (!ths) return;
    ths.forEach(th => th.classList.remove("sort-asc", "sort-desc"));
    const active = ths.find(th => th.dataset.sort === state.sortKey);
    if (active) active.classList.add(state.sortDir === "asc" ? "sort-asc" : "sort-desc");
  }

  function bind() {
    if (filterBtns && filterBtns.length > 0) {
      filterBtns.forEach(btn => {
        btn.addEventListener("click", () => {
          filterBtns.forEach(b => b.classList.remove("active"));
          btn.classList.add("active");
          state.filter = btn.dataset.filter || "all";
          render();
        });
      });
    }

    if (searchInput) {
      searchInput.addEventListener("input", (e) => {
        state.query = e.target.value || "";
        render();
      });
    }

    if (ths && ths.length > 0) {
      ths.forEach(th => {
        th.addEventListener("click", () => {
          const key = th.dataset.sort;
          if (!key) return;

          if (state.sortKey === key) {
            state.sortDir = (state.sortDir === "asc") ? "desc" : "asc";
          } else {
            state.sortKey = key;
            state.sortDir = (key === "model" || key === "rank") ? "asc" : "desc";
          }
          setSortHeaderUI();
          render();
        });
      });
    }
  }

  document.addEventListener("DOMContentLoaded", () => {
    tableBody = document.getElementById("tableBody");
    searchInput = document.getElementById("searchInput");
    filterBtns = Array.from(document.querySelectorAll(".filter-btn"));
    ths = Array.from(document.querySelectorAll("th.sortable"));

    bind();
    setSortHeaderUI();
    render();
  });
})();
  </script>
</head>

<body>
  <header>
    <div class="nav">
      <div class="brand">
        <span>MMDR-Bench</span>
        <span class="pill">MMDeepResearch-Bench</span>
      </div>

      <div class="navlinks">
        <a href="#abstract">Abstract</a>
        <a href="#introduction">Introduction</a>
        <a href="#dataset">Dataset</a>
        <a href="#method">Method</a>
        <a href="#leaderboard">Leaderboard</a>
      </div>
    </div>
  </header>

  <!-- MMMU-like centered hero -->
  <div class="hero-wrap" id="top">
    <div class="hero">
      <div class="container is-max-desktop has-text-centered">
        <h1 class="pub-title">
          MMDeepResearch-Bench: Grounded Evaluation and Alignment for Multimodal Deep Research Agents
        </h1>

        <p class="pub-subtitle">
          A benchmark of expert-crafted multimodal deep-research tasks, plus a unified evaluation pipeline for long-form,
          citation-grounded reports.
        </p>

  

        <div class="publication-links">
          <a class="button" href="paper.pdf" target="_blank" rel="noopener">
            <span class="icon">üìÑ</span><span>Paper</span>
          </a>
          <a class="button" href="https://github.com/MMDeepResearch-Bench/MMDeepResearch-bench.github.io" target="_blank" rel="noopener">
            <span class="icon">‚≠ê</span><span>Code</span>
          </a>
          <a class="button" href="#dataset">
            <span class="icon">üß©</span><span>Dataset</span>
          </a>
          <a class="button" href="#leaderboard">
            <span class="icon">üèÜ</span><span>Leaderboard</span>
          </a>
        </div>

        <div class="meta-row">
          <span class="badge">140 tasks</span>
          <span class="badge">21 domains</span>
          <span class="badge">Image‚ÄìText bundles</span>
        </div>
      </div>
    </div>
  </div>

  <!-- Abstract -->
  <section id="abstract">
    <div class="container is-max-desktop">
      <h2 class="has-text-centered">Abstract</h2>
      <div class="content has-text-justified">
        <p class="muted">
          Deep Research Agents (DRAs) generate citation-rich reports via multi-step search and synthesis, yet existing
          benchmarks mainly target text-only settings or short-form multimodal Question-and-Answering, missing end-to-end
          multimodal evidence use. We introduce MMDeepResearch-Bench (MMDR-Bench), a benchmark of 140 expert-crafted tasks
          across 21 domains, where each task provides an image‚Äìtext bundle to evaluate multimodal understanding and
          citation-grounded report generation. We further propose a unified, interpretable evaluation pipeline: FLAE
          (Formula‚ÄìLLM Adaptive Evaluation), a formula‚ÄìLLM hybrid combining reproducible text features with task-adaptive
          judging for report quality; TRACE (Trustworthy Retrieval-Aligned Citation Evaluation), which verifies Claim‚ÄìURL
          support and enforces multimodal prompt faithfulness via visual evidence fidelity; and MOSAIC (Multimodal
          Support-Aligned Integrity Check), which checks integrity between visual-referenced statements and visual
          artifacts. Experiments on 25 state-of-the-art models reveal clear trade-offs between generation quality and
          multimodal grounding. A human study shows strong alignment with expert judgments. MMDR-Bench and the associated
          evaluation framework will be publicly available after acceptance.
        </p>
      </div>
    </div>
  </section>

  <!-- Introduction -->
  <section id="introduction">
    <div class="container is-max-desktop">
      <h2 class="has-text-centered">Introduction</h2>

      <div class="content has-text-justified">
        <p class="muted">
          Deep Research Agents increasingly operate over heterogeneous evidence (web pages, charts, tables, screenshots).
          MMDR-Bench targets end-to-end multimodal deep-research: agents must interpret task images, browse to gather
          supporting sources, and write long-form reports with verifiable citations while remaining faithful to visual evidence.
        </p>

        <p class="muted">
          MMDR-Bench adds three missing pieces: <strong>(1) multimodal task instances</strong> packaged as image‚Äìtext bundles,
          <strong>(2) report-level evaluation</strong> that enforces claim‚ÄìURL verifiability, and
          <strong>(3) explicit prompt-faithfulness checks</strong> tied to visual requirements.
        </p>
      </div>

      <div class="figure-card" style="margin-top:16px;">
        <figure>
          <div class="figure-media">
            <img class="paper-fig intro" src="assets/introdanlan.png"
                 alt="MMDR-Bench evaluates multimodal deep research abilities at integrated and atomic levels (placeholder intro figure)" />
          </div>
          <figcaption>
            Figure 1: MMDR-Bench evaluates multimodal deep research at integrated and atomic levels.
          </figcaption>
        </figure>
      </div>

      <div class="figure-card" style="margin-top:16px;">
        <figure>
          <div class="figure-media">
            <img class="paper-fig intro" src="assets/bar_plot.svg" alt="Overall results teaser / bar plot" />
          </div>
          <figcaption>
            Overall MMDR score summary (from the paper). <a href="assets/bar_plot.svg" target="_blank" rel="noopener">Open full-size</a>.
          </figcaption>
        </figure>
      </div>
    </div>
  </section>

  <!-- Dataset band -->
  <div class="band">
    <div class="band-inner">
      <h1 class="band-title">MMDR-Bench Benchmark</h1>
    </div>
  </div>

  <!-- Dataset -->
  <section id="dataset">
    <div class="container is-max-desktop">
      <h2 class="has-text-centered">Dataset</h2>

      <div class="content has-text-justified">
        <p class="muted">
          MMDR-Bench includes two complementary regimes reflecting everyday workflows and analysis-heavy research settings.
          The benchmark evaluates multimodal task understanding, citation-grounded reasoning, and long-form synthesis under
          prompt-faithfulness constraints to task-provided images.
        </p>

        <p class="muted">
          <strong>Daily:</strong> 40 tasks across 11 domains, featuring screenshots, photos, and UI captures.
          <strong>Research:</strong> 100 tasks across 10 domains, featuring charts, tables, and diagrams that require longer synthesis.
        </p>

        <p class="muted">
          What is evaluated: <strong>(1) visually grounded planning</strong>, <strong>(2) claim‚ÄìURL support</strong>, and
          <strong>(3) integrity between image-referenced statements and visual artifacts</strong>.
        </p>
      </div>

      <div class="grid" style="margin-top:16px;">
        <div style="grid-column: span 6;">
          <div class="figure-card">
            <figure>
              <div class="figure-media">
                <img class="paper-fig" src="assets/distribution.svg" alt="Task distribution (placeholder)" />
              </div>
              <figcaption>Figure: Task distribution of MMDR-Bench.</figcaption>
            </figure>
          </div>
        </div>

        <div style="grid-column: span 6;">
          <div class="figure-card">
            <figure>
              <div class="figure-media">
                <img class="paper-fig" src="assets/datasamples.svg" alt="Example tasks (placeholder)" />
              </div>
              <figcaption>Figure: Two example tasks from MMDR-Bench.</figcaption>
            </figure>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Method -->
  <section id="method">
    <div class="container is-max-desktop">
      <h2 class="has-text-centered">Evaluation Method</h2>

      <div class="content has-text-justified">
        <p class="muted">
          We use a unified, interpretable 3-stage pipeline combining report quality, citation support, and image-grounded integrity:
          <strong>FLAE</strong>, <strong>TRACE</strong>, and a gated <strong>MOSAIC</strong> stage.
        </p>
      </div>

      <div class="grid" style="margin-top:14px;">
        <div class="card" style="grid-column: span 4;">
          <h3>FLAE</h3>
          <p class="muted">
            Formula‚ÄìLLM hybrid: reproducible text features + task-aware judging, fused with an adaptive coefficient.
          </p>
        </div>
        <div class="card" style="grid-column: span 4;">
          <h3>TRACE</h3>
          <p class="muted">
            Verifies claim‚ÄìURL support and enforces multimodal prompt faithfulness via visual evidence fidelity.
          </p>
        </div>
        <div class="card" style="grid-column: span 4;">
          <h3>MOSAIC (Gated)</h3>
          <p class="muted">
            Checks integrity between visual-referenced statements and visual artifacts; activated only when earlier stages are scorable.
          </p>
        </div>
      </div>

      <div class="figure-card" style="margin-top:16px;">
        <figure>
          <div class="figure-media">
            <img class="paper-fig pipeline" src="assets/pipeline.png" alt="MMDR-Bench evaluation pipeline" />
          </div>
          <figcaption>
            Evaluation pipeline (from the paper). <a href="assets/pipeline.png" target="_blank" rel="noopener">Open full-size</a>.
          </figcaption>
        </figure>
      </div>
    </div>
  </section>

  <!-- Results band -->
  <div class="band">
    <div class="band-inner">
      <h1 class="band-title">Experiment Results</h1>
    </div>
  </div>

  <!-- Experiments -->
  <section id="experiments">
    <div class="container is-max-desktop">
      <h2 class="has-text-centered">Experiments</h2>

      <div class="content has-text-justified">
        <p class="muted">
          Results highlight cross-metric trade-offs between writing quality, citation discipline, and multimodal grounding.
          Use the interactive leaderboard to sort and compare systems.
        </p>
      </div>

      <h3 id="leaderboard" style="margin-top:10px;">Leaderboard</h3>
      <div class="leaderboard-container">
        <div class="leaderboard-header">
          <h3>üèÜ Model Rankings</h3>
          <p>Overall and per-metric results across evaluated models</p>
        </div>

        <div class="controls">
          <div class="filter-group">
            <label style="font-weight: 600; font-size: 13px;">Category:</label>
            <button class="filter-btn active" data-filter="all">All Models</button>
            <button class="filter-btn" data-filter="single">Single-Modal</button>
            <button class="filter-btn" data-filter="multimodal">Multimodal</button>
            <button class="filter-btn" data-filter="agent">Deep Research</button>
          </div>

          <div class="search-box">
            <input type="text" id="searchInput" placeholder="Search models...">
          </div>
        </div>

        <div class="table-container">
          <table class="leaderboard-table" id="leaderboardTable">
            <thead>
              <tr>
                <th class="sortable" data-sort="model">Model</th>
                <th class="sortable" data-sort="overall">Overall</th>
                <th class="metric-group sortable" data-sort="read" title="Readability">Read.</th>
                <th class="sortable" data-sort="insh" title="Insightfulness">Insh.</th>
                <th class="sortable" data-sort="stru" title="Structure">Stru.</th>
                <th class="metric-group sortable" data-sort="vef" title="Visual Evidence Fidelity">Vef.</th>
                <th class="sortable" data-sort="con" title="Consistency">Con.</th>
                <th class="sortable" data-sort="cov" title="Coverage">Cov.</th>
                <th class="sortable" data-sort="fid" title="Fidelity">Fid.</th>
                <th class="metric-group sortable" data-sort="sem" title="Semantic">Sem.</th>
                <th class="sortable" data-sort="acc" title="Accuracy">Acc.</th>
                <th class="sortable" data-sort="vqa" title="VQA">VQA</th>
              </tr>
            </thead>
            <tbody id="tableBody"></tbody>
          </table>
        </div>
      </div>

      <h3 style="margin-top:26px;">Key Findings</h3>
      <div class="content has-text-justified">
        <p class="muted">
          <strong>Vision helps only when it is reliable as evidence.</strong> Noisy or auxiliary visuals can seed incorrect premises that propagate through retrieval and synthesis.
        </p>
        <p class="muted">
          <strong>Multimodal alignment and citation grounding can diverge.</strong> Better visual grounding does not automatically imply stronger claim‚ÄìURL support.
        </p>
        <p class="muted">
          <strong>Tool use helps, but strong backbones and richer retrieval matter most.</strong> Agents can amplify backbones, but cannot replace them.
        </p>
      </div>

      <div class="figure-card" style="margin-top:14px;">
        <figure>
          <div class="figure-media">
            <img class="paper-fig" src="assets/unified_failure_analysis.svg" alt="Optional figure (placeholder)" />
          </div>
          <figcaption>Optional: main analysis snapshot.</figcaption>
        </figure>
      </div>

      <h3 style="margin-top:26px;">Conclusion</h3>
      <div class="content has-text-justified">
        <p class="muted">
          MMDR-Bench targets end-to-end multimodal deep research by pairing image‚Äìtext tasks with a unified evaluation
          pipeline that measures report quality, citation-grounded faithfulness, and text‚Äìvisual integrity. Results across
          diverse systems show persistent trade-offs between writing quality, citation discipline, and multimodal grounding.
        </p>
      </div>

      <!-- ‚úÖ Example is INSIDE the section + container -->
      <h3 style="margin-top:22px;">Example</h3>

      <div class="grid example-grid" style="margin-top:12px;">
        <div class="example-col">
          <figure class="figure-card">
            <div class="figure-media">
              <img class="paper-fig example-fig"
                   src="assets/bad.svg"
                   alt="Daily-task example: screenshot-based multimodal deep research" />
            </div>
            <figcaption>
              <strong>Daily-task example.</strong>
              Screenshot-based multimodal task requiring correct visual interpretation and
              citation-grounded reporting.
            </figcaption>
          </figure>
        </div>

        <div class="example-col">
          <figure class="figure-card">
            <div class="figure-media">
              <img class="paper-fig example-fig"
                   src="assets/good.svg"
                   alt="Research-task example: chart-based multimodal deep research" />
            </div>
            <figcaption>
              <strong>Research-task example.</strong>
              Chart-driven task demanding visual-faithful reasoning, multi-step retrieval,
              and long-form synthesis.
            </figcaption>
          </figure>
        </div>
      </div>
      <!-- ‚úÖ Example end -->
    </div>
  </section>

  
  <footer>
    <div class="footer-inner">
      <div>¬© 2026 MMDR-Bench</div>
      <div class="muted2">
        <a href="https://github.com/MMDeepResearch-Bench/MMDeepResearch-bench.github.io"
           target="_blank" rel="noopener">GitHub Pages</a>
      </div>
    </div>
  </footer>
</body>
</html>





